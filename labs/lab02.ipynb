{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b41895cb",
   "metadata": {},
   "source": [
    "# Lab 2: A Brief Introduction to MLflow \n",
    "\n",
    "## Goal\n",
    "Setup the MLflow, and get familiar with the basics.\n",
    "Inspired by the [hands-on tutorial from MLflow](https://mlflow.org/docs/latest/ml/getting-started/logging-first-model/).\n",
    "\n",
    "## About MLflow\n",
    "\n",
    "MLflow is an open-source platform designed to manage the machine learning lifecycle, including:\n",
    "\n",
    "* **Experiment tracking:** log parameters, metrics, artifacts (models, plots, datasets).\n",
    "\n",
    "* **Model packaging:** save models in a standard format for deployment.\n",
    "\n",
    "* **Model registry:** register, version, and stage models (e.g., “Staging” or “Production”).\n",
    "\n",
    "* **Deployment:** serve models via REST APIs or integrate with other platforms.\n",
    "\n",
    "\n",
    "MLflow supports multiple ways to track experiments and runs:\n",
    "\n",
    "* Local file system (default)\n",
    "\n",
    "    * Stores run data under mlruns/ in the project directory.\n",
    "\n",
    "    * Easy for experimentation on a single machine.\n",
    "\n",
    "* MLflow Tracking Server\n",
    "\n",
    "    * Centralized server for multiple users.\n",
    "\n",
    "    * Can be backed by a database (e.g., MySQL, PostgreSQL) for runs metadata.\n",
    "\n",
    "    * Artifacts can be stored in cloud storage (S3, Azure Blob, GCS) or network drives.\n",
    "\n",
    "* Cloud-hosted services\n",
    "\n",
    "    * Managed platforms like Databricks, AWS SageMaker, or GCP AI Platform integrate MLflow tracking.\n",
    "\n",
    "    * Provide collaboration, access control, and remote artifact storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1eb4f",
   "metadata": {},
   "source": [
    "## Part 1: Setup & Foundations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fedf81",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install 'mlflow[extras]<3' hyperopt tensorflow scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8182fa3",
   "metadata": {},
   "source": [
    "Open a console and launch a MLflow tracking server:\n",
    "\n",
    "```\n",
    "mlflow server --host 127.0.0.1 --port 8080\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbb5528",
   "metadata": {},
   "source": [
    "## Part 2: Data & Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a578a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Sets the current active experiment to the \"Iris_Models\" experiment and\n",
    "# returns the Experiment metadata\n",
    "iris_experiment = mlflow.set_experiment(\"Iris_Models\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"iris_rf_test\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"rf_iris\"\n",
    "\n",
    "# Load the data and split it into training and validation sets\n",
    "iris = load_iris()\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 50,\n",
    "    \"max_depth\": 3,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"min_samples_leaf\": 2,\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": False,\n",
    "    \"random_state\": 888,\n",
    "}\n",
    "\n",
    "# Train the RandomForestRegressor\n",
    "rf = RandomForestRegressor(**params)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "# Calculate error metrics\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "# Assemble the metrics we're going to write into a collection\n",
    "metrics = {\"mae\": mae, \"mse\": mse, \"rmse\": rmse, \"r2\": r2}\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(sk_model=rf, input_example=X_val, artifact_path=artifact_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeb19cf",
   "metadata": {},
   "source": [
    "In order to see the results of our run, we can navigate to the MLflow UI. Since we have already started the Tracking Server at http://localhost:8080, we can simply navigate to that URL in our browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e2e18",
   "metadata": {},
   "source": [
    "### Analyze Results in MLflow UI\n",
    "In order to see the results of our run, we can navigate to the MLflow UI. Since we have already started the Tracking Server at http://localhost:8080, we can simply navigate to that URL in our browser.\n",
    "\n",
    "You can also run following command in a separate terminal and keep it running:\n",
    "```\n",
    "mlflow ui --port 5000\n",
    "```\n",
    "Your MLflow UI will be available at http://localhost:5000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed8a365",
   "metadata": {},
   "source": [
    "## Part 3: Hyperparameter Tuning & Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e263535",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69600599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "\n",
    "\n",
    "experiment_name = \"iris-rf-optimization\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "print(f\"Starting hyperparameter optimization experiment: {experiment_name}\")\n",
    "print(\"This will run 15 trials to find optimal hyperparameters...\")\n",
    "\n",
    "# Define search space\n",
    "search_space = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [10, 50, 100]),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [3, 5, 10]),\n",
    "}\n",
    "\n",
    "# Define objective function\n",
    "def objective(params):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Log parameters\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Train model\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=int(params[\"n_estimators\"]),\n",
    "            max_depth=params[\"max_depth\"],\n",
    "            random_state=42,\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_val)\n",
    "        # Calculate error metrics\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        # Assemble the metrics we're going to write into a collection\n",
    "        metrics = {\"mae\": mae, \"mse\": mse, \"rmse\": rmse, \"r2\": r2}\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(model, input_example=X_val, artifact_path=\"model\")\n",
    "\n",
    "    return {\"loss\": rmse, \"status\": STATUS_OK}\n",
    "\n",
    "# Run optimization\n",
    "trials = Trials()\n",
    "\n",
    "with mlflow.start_run(run_name=\"hyperparameter-sweep\"):\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"max_evaluations\": 15,\n",
    "            \"objective_metric\": \"rmse\",\n",
    "            \"dataset\": \"iris\",\n",
    "            \"model_type\": \"RandomForestRegressor\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    best_params = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=15,\n",
    "        trials=trials,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    best_trial = min(trials.results, key=lambda x: x[\"loss\"])\n",
    "    best_rmse = best_trial[\"loss\"]\n",
    "\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"best_n_estimators\": best_params[\"n_estimators\"],\n",
    "            \"best_max_depth\": best_params[\"max_depth\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    mlflow.log_metrics(\n",
    "        {\n",
    "            \"best_rmse\": best_rmse,\n",
    "            \"total_trials\": len(trials.trials),\n",
    "            \"optimization_completed\": 1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best RMSE: {best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a2fb8",
   "metadata": {},
   "source": [
    "### Register Your Best Model & Deploy It Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7391a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can either use the UI to find and register the best model or do it via Python:\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiment = client.get_experiment_by_name(\"iris-rf-optimization\")\n",
    "runs = client.search_runs(experiment.experiment_id, order_by=[\"metrics.rmse ASC\"])\n",
    "best_run = runs[0]\n",
    "\n",
    "print(\"Best run ID:\", best_run.info.run_id)\n",
    "print(\"RMSE:\", best_run.data.metrics[\"rmse\"])\n",
    "\n",
    "# Load model from MLflow\n",
    "model_uri = f\"runs:/{best_run.info.run_id}/model\"\n",
    "best_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# Test prediction\n",
    "sample = X_val[0].reshape(1, -1)\n",
    "prediction = best_model.predict(sample)\n",
    "print(f\"Prediction: {prediction[0]}\")\n",
    "print(f\"Ground truth: {y_val[0]}\")\n",
    "\n",
    "# Register best model\n",
    "model_name = \"Iris-RandomForest\"\n",
    "print(f\"Registering best model: {model_name}\")\n",
    "registered_model = mlflow.register_model(model_uri, model_name)\n",
    "\n",
    "print(f\"Model registered: {registered_model.name}, version {registered_model.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bc5cf0",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Serve the model locally (choose the version number you registered) - run in a separate terminal:\n",
    "export MLFLOW_TRACKING_URI=http://localhost:8080\n",
    "mlflow models serve -m \"models:/Iris-RandomForest/1\" -p 5002 --env-manager conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then test the deployment with Python\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "data = json.dumps({\"instances\": X_val[:2].tolist()})\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "response = requests.post(\"http://127.0.0.1:5002/invocations\", data=data, headers=headers)\n",
    "print(\"Predictions:\", response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc27bd",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# We can also build a Docker image for cloud deployment\n",
    "mlflow models build-docker --model-uri \"models:/Iris-RandomForest/1\" --name \"iris-rf-api\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-eng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
